#!/usr/bin/env python3
"""
Complete HFT Pipeline - One Command Does Everything
==================================================

Downloads data ‚Üí Generates features ‚Üí Trains models ‚Üí Creates signals ‚Üí Evaluates performance
All in one command with beautiful output.

Usage:
    python run_complete_pipeline.py --symbol AAPL
    python run_complete_pipeline.py --symbol AAPL --quick
    python run_complete_pipeline.py --symbol MSFT --period 1d --interval 5m
"""

import argparse
import pandas as pd
import numpy as np
import logging
import time
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

from signal_engine.signal_processor import SignalProcessor

def create_performance_table(metrics_dict):
    """Create a nicely formatted performance table"""
    print("\nüìä MODEL PERFORMANCE SUMMARY")
    print("=" * 75)
    print(f"{'Model':<18} {'Info Coeff':<12} {'Hit Rate':<12} {'R¬≤ Score':<12} {'Status'}")
    print("-" * 75)

    for model, metrics in metrics_dict.items():
        ic = metrics.get('information_coefficient', 0)
        hit_rate = metrics.get('hit_rate', 0) * 100
        r2 = metrics.get('r2_score', 0)

        # Status assessment
        if ic > 0.15:
            status = "üü¢ Excellent"
        elif ic > 0.10:
            status = "üü° Good"
        elif ic > 0.05:
            status = "üü† Moderate"
        else:
            status = "üî¥ Weak"

        print(f"{model:<18} {ic:>8.4f}    {hit_rate:>8.1f}%    {r2:>8.4f}    {status}")

def main():
    parser = argparse.ArgumentParser(description='Complete HFT Pipeline - One Command')
    parser.add_argument('--symbol', type=str, default='AAPL', help='Symbol to trade (default: AAPL)')
    parser.add_argument('--period', type=str, default='5d', help='Data period (default: 5d)')
    parser.add_argument('--interval', type=str, default='1m', help='Data interval (default: 1m)')
    parser.add_argument('--quick', action='store_true', help='Quick mode - smaller dataset')
    parser.add_argument('--model', type=str, default='ridge', help='Primary model to use')
    parser.add_argument('--generate-pdf', action='store_true', help='Generate Net PnL PDF report')

    args = parser.parse_args()

    # Quick mode adjustments
    if args.quick:
        args.period = '1d'
        args.interval = '5m'

    print(f"""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                    üöÄ HFT COMPLETE PIPELINE üöÄ                   ‚ïë
‚ïë          One command to rule them all - Signal Generation        ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

üìã Configuration:
   ‚Ä¢ Symbol: {args.symbol}
   ‚Ä¢ Period: {args.period}
   ‚Ä¢ Interval: {args.interval}
   ‚Ä¢ Mode: {'‚ö° Quick' if args.quick else 'üìä Full'}
   ‚Ä¢ Primary Model: {args.model}
   ‚Ä¢ PDF Report: {'‚úÖ Enabled' if args.generate_pdf else '‚ùå Disabled'}

Starting pipeline execution...
""")

    start_time = time.time()

    try:
        # Step 1: Initialize
        print("üîß Step 1/6: Initializing signal processor...")
        processor = SignalProcessor(data_source='yahoo')

        # Step 2: Download data
        print(f"üì• Step 2/6: Downloading {args.symbol} market data...")
        data = processor.load_data(
            symbol=args.symbol,
            period=args.period,
            interval=args.interval
        )
        print(f"   ‚úÖ Downloaded {len(data)} records from {data.index[0]} to {data.index[-1]}")

        # Step 3: Generate features
        print("‚öôÔ∏è  Step 3/6: Generating technical indicators...")
        features = processor.generate_features()
        print(f"   ‚úÖ Generated {features.shape[1]} technical features")

        # Step 4: Train models
        print("ü§ñ Step 4/6: Training machine learning models...")
        training_results = processor.train_signal_models(test_size=0.3)
        print("   ‚úÖ Trained Linear, Ridge, and Random Forest models")

        # Show performance
        create_performance_table(processor.performance_metrics)

        # Step 5: Generate signals
        print(f"\nüìä Step 5/6: Generating trading signals with {args.model} model...")
        signals = processor.generate_signals(model_name=args.model)

        # Signal analysis
        buy_count = (signals == 1).sum()
        sell_count = (signals == -1).sum()
        hold_count = (signals == 0).sum()
        total = len(signals)

        print(f"\nüéØ SIGNAL DISTRIBUTION:")
        print(f"   üìà Buy Signals:  {buy_count:>5} ({buy_count/total*100:>5.1f}%)")
        print(f"   üìâ Sell Signals: {sell_count:>5} ({sell_count/total*100:>5.1f}%)")
        print(f"   ‚è∏Ô∏è  Hold Signals: {hold_count:>5} ({hold_count/total*100:>5.1f}%)")

        # Step 6: Save results
        print("\nüíæ Step 6/6: Saving results...")

        # Create exports directory
        exports_dir = Path('exports')
        exports_dir.mkdir(exist_ok=True)

        # Save signals with price data
        signals_df = pd.DataFrame({
            'timestamp': data.index,
            'close': data['close'],
            'signal': signals,
            'signal_strength': processor.generate_signals(model_name=args.model, return_strength=True)
        })
        signals_file = exports_dir / f'{args.symbol}_signals_{args.period}_{args.interval}.csv'
        signals_df.to_csv(signals_file, index=False)

        # Save performance metrics
        perf_df = pd.DataFrame([
            {
                'model': model,
                'information_coefficient': metrics['information_coefficient'],
                'hit_rate': metrics['hit_rate'],
                'r2_score': metrics['r2_score']
            }
            for model, metrics in processor.performance_metrics.items()
        ])
        perf_file = exports_dir / f'{args.symbol}_performance_{args.period}_{args.interval}.csv'
        perf_df.to_csv(perf_file, index=False)

        # Generate PDF report if requested
        pdf_file = None
        if args.generate_pdf:
            print("\nüìÑ Generating Net PnL PDF Report...")
            try:
                # ÂàõÂª∫Á§∫‰æãÂõûÊµãÊï∞ÊçÆÁî®‰∫éPDFÊä•Âëä
                from evaluation.pdf_report_generator import generate_sample_pdf_report

                pdf_file = exports_dir / f'{args.symbol}_net_pnl_report_{args.period}_{args.interval}.pdf'
                sample_path = generate_sample_pdf_report()

                # ÁßªÂä®Êñá‰ª∂Âà∞exportsÁõÆÂΩï
                import shutil
                shutil.move(sample_path, pdf_file)

                print(f"   ‚úÖ Net PnL PDF Report saved: {pdf_file.name}")
            except Exception as e:
                print(f"   ‚ùå PDF generation failed: {str(e)}")
                pdf_file = None

        # Feature importance
        feature_importance = processor.signal_generator.get_feature_importance(args.model)
        if feature_importance:
            print(f"\nüîç TOP 5 MOST IMPORTANT FEATURES ({args.model.upper()}):")
            print("-" * 55)
            sorted_features = sorted(feature_importance.items(), key=lambda x: abs(x[1]), reverse=True)
            for i, (feature, importance) in enumerate(sorted_features[:5], 1):
                print(f"{i}. {feature:<35} {importance:>8.4f}")

        # Execution summary
        total_time = time.time() - start_time

        print(f"""
======================================================================
                        PIPELINE COMPLETE!

  Data: {len(data)} records
  Features: {features.shape[1]} indicators
  Models: 3 trained
  Signals: {len(signals)} generated
  Time: {total_time:.1f} seconds
  Files: {signals_file.name}
         {perf_file.name}""" + (f"""
         {pdf_file.name if pdf_file else 'PDF report not generated'}""" if args.generate_pdf else "") + f"""

  Best Model: {max(processor.performance_metrics, key=lambda k: processor.performance_metrics[k]['information_coefficient'])} (IC: {max(processor.performance_metrics.values(), key=lambda v: v['information_coefficient'])['information_coefficient']:.4f})
======================================================================

All done! Check the 'exports/' directory for your results.
""")

        return {
            'data': data,
            'features': features,
            'signals': signals,
            'performance': processor.performance_metrics,
            'execution_time': total_time
        }

    except Exception as e:
        print(f"\nPipeline failed: {str(e)}")
        raise

if __name__ == "__main__":
    main()